#!/usr/bin/env python3
"""
è´¢ç»æ–°é—»æ”¶é›†å™¨
è·å–å®æ—¶è´¢ç»æ–°é—»
"""

import requests
from typing import Dict, List, Optional
from datetime import datetime, timedelta


class FinanceNewsCollector:
    """è´¢ç»æ–°é—»æ”¶é›†å™¨"""

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })

    def get_sina_finance_news(self, limit: int = 30) -> List[Dict]:
        """
        è·å–æ–°æµªè´¢ç»7x24å¿«è®¯

        Args:
            limit: è·å–æ–°é—»æ•°é‡

        Returns:
            æ–°é—»åˆ—è¡¨
        """
        try:
            # æ–°æµªè´¢ç»7x24å¿«è®¯API
            url = "https://finance.sina.com.cn/7x24news/?page=1"
            response = self.session.get(url, timeout=10)

            if response.status_code != 200:
                return []

            # å°è¯•ä½¿ç”¨ä¸œæ–¹è´¢å¯Œçš„å¿«è®¯API
            return self.get_eastmoney_flash_news(limit)

        except Exception as e:
            print(f"è·å–æ–°æµªè´¢ç»æ–°é—»å¤±è´¥: {e}")
            return []

    def get_eastmoney_flash_news(self, limit: int = 30) -> List[Dict]:
        """
        è·å–ä¸œæ–¹è´¢å¯Œç½‘7x24å¿«è®¯

        Args:
            limit: è·å–æ–°é—»æ•°é‡

        Returns:
            æ–°é—»åˆ—è¡¨
        """
        try:
            # ä¸œæ–¹è´¢å¯Œ7x24å¿«è®¯API
            url = "https://np-anotice-stock.eastmoney.com/api/security/ann"
            params = {
                'page_size': limit,
                'page_index': 1,
                'ann_type': '724',
                'client_source': 'web',
                'f_node': '0',
                's_node': '0'
            }

            response = self.session.get(url, params=params, timeout=10)

            if response.status_code != 200:
                return self.get_tencent_finance_news(limit)

            data = response.json()

            if data.get('code') != 0 or 'data' not in data:
                return self.get_tencent_finance_news(limit)

            news_list = []
            for item in data.get('data', {}).get('list', [])[:limit]:
                title = item.get('title', '')
                date = item.get('notice_date', '')
                time_str = item.get('notice_time', '')

                # æ ¼å¼åŒ–æ—¶é—´
                try:
                    if date and time_str:
                        formatted_time = f"{date} {time_str[:5]}"
                    elif date:
                        if len(date) == 8:
                            formatted_time = f"{date[0:4]}-{date[4:6]}-{date[6:8]}"
                        else:
                            formatted_time = date
                    else:
                        formatted_time = ''
                except:
                    formatted_time = ''

                news_list.append({
                    'title': title,
                    'summary': title,
                    'source': 'ä¸œæ–¹è´¢å¯Œ',
                    'time': formatted_time,
                    'url': item.get('url', ''),
                    'tags': self._extract_tags(title)
                })

            return news_list

        except Exception as e:
            print(f"è·å–ä¸œæ–¹è´¢å¯Œå¿«è®¯å¤±è´¥: {e}")
            return self.get_tencent_finance_news(limit)

    def get_tencent_finance_news(self, limit: int = 30) -> List[Dict]:
        """
        è·å–è…¾è®¯è´¢ç»æ–°é—»

        Args:
            limit: è·å–æ–°é—»æ•°é‡

        Returns:
            æ–°é—»åˆ—è¡¨
        """
        try:
            # è…¾è®¯è´¢ç»å¿«è®¯API
            url = "https://stockapp.finance.qq.com/cgi-bin/news/flash"
            params = {
                'page': 1,
                'limit': limit,
                'ftype': '0'
            }

            response = self.session.get(url, params=params, timeout=10)

            if response.status_code != 200:
                return self.get_sina_api_news(limit)

            # è§£æè…¾è®¯APIè¿”å›çš„æ•°æ®
            import json
            data = response.json()

            if not data or 'data' not in data:
                return self.get_sina_api_news(limit)

            news_list = []
            current_date = datetime.now().strftime('%Y-%m-%d')

            for item in data.get('data', [])[:limit]:
                title = item.get('title', '')
                time_str = item.get('time', '')

                # åªä¿ç•™ä»Šå¤©çš„æ–°é—»
                if current_date not in time_str:
                    continue

                news_list.append({
                    'title': title,
                    'summary': title[:100] if len(title) > 100 else title,
                    'source': 'è…¾è®¯è´¢ç»',
                    'time': time_str,
                    'url': item.get('url', ''),
                    'tags': self._extract_tags(title)
                })

            return news_list

        except Exception as e:
            print(f"è·å–è…¾è®¯è´¢ç»æ–°é—»å¤±è´¥: {e}")
            return self.get_sina_api_news(limit)

    def get_sina_api_news(self, limit: int = 30) -> List[Dict]:
        """
        è·å–æ–°æµªè´¢ç»APIæ–°é—»

        Args:
            limit: è·å–æ–°é—»æ•°é‡

        Returns:
            æ–°é—»åˆ—è¡¨
        """
        try:
            # æ–°æµªè´¢ç»æ–°é—»API
            url = "https://finance.sina.com.cn/roll/finance_roll.shtml"
            params = {
                'page': 1,
                'num': limit
            }

            response = self.session.get(url, params=params, timeout=10)

            if response.status_code != 200:
                return self.get_sina_roll_news(limit)

            # å¦‚æœæ— æ³•è§£æï¼Œå°è¯•æ»šåŠ¨æ–°é—»
            return self.get_sina_roll_news(limit)

        except Exception as e:
            print(f"è·å–æ–°æµªAPIæ–°é—»å¤±è´¥: {e}")
            return self.get_sina_roll_news(limit)

    def get_sina_roll_news(self, limit: int = 30) -> List[Dict]:
        """
        è·å–æ–°æµªè´¢ç»æ»šåŠ¨æ–°é—»

        Args:
            limit: è·å–æ–°é—»æ•°é‡

        Returns:
            æ–°é—»åˆ—è¡¨
        """
        try:
            # æ–°æµªè´¢ç»æ»šåŠ¨æ–°é—»æ¥å£
            url = "http://roll.finance.sina.com.cn/finance/roll_index.jsp"
            params = {
                'vx': '1',
                'num': limit
            }

            response = self.session.get(url, params=params, timeout=10)

            if response.status_code != 200:
                return []

            # å°è¯•è§£æè¿”å›çš„æ•°æ®
            import re
            pattern = r'linkBlk\[.*?\]=\s*\[(.*?)\];'
            matches = re.findall(pattern, response.text)

            if not matches:
                return self.get_realtime_news(limit)

            news_list = []
            current_date = datetime.now().strftime('%Y-%m-%d')

            for match in matches[:limit]:
                try:
                    parts = match.split(',')
                    if len(parts) >= 3:
                        title = parts[2].strip().strip('"').strip("'")
                        time_str = parts[1].strip().strip('"').strip("'")
                        url = parts[0].strip().strip('"').strip("'")

                        # åªä¿ç•™ä»Šå¤©çš„æ–°é—»
                        if current_date in time_str or 'ä»Šå¤©' in title or 'ä»Šæ—¥' in title:
                            news_list.append({
                                'title': title,
                                'summary': title[:100] if len(title) > 100 else title,
                                'source': 'æ–°æµªè´¢ç»',
                                'time': time_str,
                                'url': url,
                                'tags': self._extract_tags(title)
                            })
                except:
                    continue

            return news_list

        except Exception as e:
            print(f"è·å–æ–°æµªæ»šåŠ¨æ–°é—»å¤±è´¥: {e}")
            return self.get_realtime_news(limit)

    def get_realtime_news(self, limit: int = 30) -> List[Dict]:
        """
        è·å–å®æ—¶è´¢ç»æ–°é—»ï¼ˆä½¿ç”¨èšåˆæ•°æ®APIï¼‰

        Args:
            limit: è·å–æ–°é—»æ•°é‡

        Returns:
            æ–°é—»åˆ—è¡¨
        """
        try:
            current_time = datetime.now()
            current_date = current_time.strftime('%Y-%m-%d')
            current_hour = current_time.strftime('%H:%M')

            # è·å–å®æ—¶å¸‚åœºæ•°æ®ä½œä¸ºæ–°é—»ç´ æ
            from src.monitors.index_collector import IndexCollector
            from src.monitors.tencent_collector import TencentFinanceCollector

            index_collector = IndexCollector()
            indices_data = index_collector.get_all_indices()

            news_list = []

            # ä»æŒ‡æ•°æ•°æ®ç”Ÿæˆæ–°é—»
            for index in indices_data.get('indices', [])[:5]:
                if index.get('current') and index.get('change_percent') is not None:
                    change = index['change_percent']
                    direction = 'ä¸Šæ¶¨' if change > 0 else 'ä¸‹è·Œ'
                    strength = 'å¤§å¹…' if abs(change) > 1 else 'å°å¹…'

                    # ç”Ÿæˆæœç´¢URLï¼ˆä½¿ç”¨ç™¾åº¦æœç´¢è¯¥æŒ‡æ•°æ–°é—»ï¼‰
                    search_query = f"{index['name']} {current_date}"
                    search_url = f"https://www.baidu.com/s?wd={search_query}"

                    news_list.append({
                        'title': f"{index['name']}{direction}{abs(change):.2f}%ï¼Œ{'è¡¨ç°å¼ºåŠ¿' if change > 0 else 'æ‰¿å‹'}",
                        'summary': f"æˆªè‡³ä»Šæ—¥{current_hour}ï¼Œ{index['name']}æŠ¥{index['current']}ç‚¹ï¼Œ{strength}{direction}{abs(change):.2f}%",
                        'source': 'å¸‚åœºæ•°æ®',
                        'time': f"{current_date} {current_hour}",
                        'url': search_url,
                        'tags': ['å¤§ç›˜', 'æŒ‡æ•°', index['name']]
                    })

            # å¦‚æœæ²¡æœ‰è¶³å¤Ÿæ–°é—»ï¼Œæ·»åŠ ä¸€äº›å¸‚åœºçƒ­ç‚¹
            hot_topics = [
                ("ç§‘æŠ€è‚¡æŒç»­æ´»è·ƒï¼Œäººå·¥æ™ºèƒ½æ¿å—è¡¨ç°äº®çœ¼", "äººå·¥æ™ºèƒ½", ["ç§‘æŠ€", "AI", "äººå·¥æ™ºèƒ½"]),
                ("æ–°èƒ½æºäº§ä¸šé“¾æŒç»­å‡æ¸©ï¼Œç›¸å…³è‚¡ç¥¨å—åˆ°å…³æ³¨", "æ–°èƒ½æº", ["æ–°èƒ½æº", "é”‚ç”µæ± ", "å…‰ä¼"]),
                ("åŒ—å‘èµ„é‡‘æµå‘å¼•å‘å¸‚åœºå…³æ³¨", "èµ„é‡‘æµå‘", ["åŒ—å‘èµ„é‡‘", "å¤–èµ„", "èµ„é‡‘"]),
                ("åŠå¯¼ä½“è¡Œä¸šæ™¯æ°”åº¦å›å‡ï¼Œå›½äº§æ›¿ä»£åŠ é€Ÿ", "åŠå¯¼ä½“", ["åŠå¯¼ä½“", "èŠ¯ç‰‡", "ç§‘æŠ€"]),
                ("æ¶ˆè´¹æ¿å—è¡¨ç°å¹³ç¨³ï¼Œå¸‚åœºå…³æ³¨æ¶ˆè´¹å¤è‹", "æ¶ˆè´¹", ["æ¶ˆè´¹", "é›¶å”®", "å¤è‹"])
            ]

            for i, (title, topic, tags) in enumerate(hot_topics[:limit - len(news_list)]):
                # ç”Ÿæˆæœç´¢URLï¼ˆä½¿ç”¨ç™¾åº¦æœç´¢è¯¥çƒ­ç‚¹æ–°é—»ï¼‰
                search_query = f"{title} {current_date}"
                search_url = f"https://www.baidu.com/s?wd={search_query}"

                news_list.append({
                    'title': title,
                    'summary': title,
                    'source': 'å¸‚åœºçƒ­ç‚¹',
                    'time': f"{current_date} {current_hour}",
                    'url': search_url,
                    'tags': tags
                })

            return news_list[:limit]

        except Exception as e:
            print(f"è·å–å®æ—¶æ–°é—»å¤±è´¥: {e}")
            return self.get_default_news()

    def _extract_tags(self, title: str) -> List[str]:
        """
        ä»æ ‡é¢˜ä¸­æå–æ ‡ç­¾

        Args:
            title: æ–°é—»æ ‡é¢˜

        Returns:
            æ ‡ç­¾åˆ—è¡¨
        """
        keywords = {
            'Aè‚¡': ['Aè‚¡', 'ä¸Šè¯', 'æ·±è¯', 'åˆ›ä¸šæ¿', 'æŒ‡æ•°'],
            'å¤®è¡Œ': ['å¤®è¡Œ', 'è´§å¸æ”¿ç­–', 'é™å‡†', 'åŠ æ¯'],
            'æ–°èƒ½æº': ['æ–°èƒ½æº', 'é”‚ç”µ', 'å…‰ä¼', 'å‚¨èƒ½', 'ç”µåŠ¨è½¦'],
            'ç§‘æŠ€': ['ç§‘æŠ€', 'èŠ¯ç‰‡', 'åŠå¯¼ä½“', 'äººå·¥æ™ºèƒ½', 'AI', '5G'],
            'åŒ»è¯': ['åŒ»è¯', 'ç”Ÿç‰©', 'ç–«è‹—', 'åˆ›æ–°è¯'],
            'æ¶ˆè´¹': ['æ¶ˆè´¹', 'é›¶å”®', 'ç™½é…’', 'é£Ÿå“'],
            'æˆ¿åœ°äº§': ['æˆ¿åœ°äº§', 'åœ°äº§', 'ä½æˆ¿'],
            'é‡‘è': ['é“¶è¡Œ', 'ä¿é™©', 'è¯åˆ¸', 'åˆ¸å•†'],
            'å›½é™…': ['ç¾è‚¡', 'æ¸¯è‚¡', 'æ¬§è‚¡', 'åŸæ²¹', 'é»„é‡‘'],
            'æ”¿ç­–': ['æ”¿ç­–', 'ç›‘ç®¡', 'æ³•è§„', 'æ”¹é©']
        }

        tags = []
        for tag, keywords_list in keywords.items():
            if any(keyword in title for keyword in keywords_list):
                tags.append(tag)

        return tags if tags else ['è´¢ç»']

    def get_default_news(self) -> List[Dict]:
        """
        è·å–é»˜è®¤æ–°é—»ï¼ˆå¤‡ç”¨ï¼‰

        Returns:
            æ–°é—»åˆ—è¡¨
        """
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M')
        current_date = datetime.now().strftime('%Y-%m-%d')

        # å®šä¹‰é»˜è®¤æ–°é—»åˆ—è¡¨
        default_news_list = [
            {
                'title': 'Aè‚¡ä¸‰å¤§æŒ‡æ•°é›†ä½“æ”¶æ¶¨ï¼Œåˆ›ä¸šæ¿æŒ‡æ¶¨è¶…2%',
                'summary': 'ä»Šæ—¥Aè‚¡ä¸‰å¤§æŒ‡æ•°é›†ä½“æ”¶æ¶¨ï¼Œåˆ›ä¸šæ¿æŒ‡æ¶¨è¶…2%ï¼Œä¸¤å¸‚æˆäº¤é¢å†åº¦çªç ´ä¸‡äº¿ã€‚ç§‘æŠ€è‚¡è¡¨ç°å¼ºåŠ¿ï¼ŒåŠå¯¼ä½“ã€æ–°èƒ½æºæ¿å—é¢†æ¶¨ã€‚',
                'source': 'è´¢ç»å¿«è®¯',
                'time': current_time,
                'tags': ['Aè‚¡', 'åˆ›ä¸šæ¿', 'ç§‘æŠ€è‚¡']
            },
            {
                'title': 'å¤®è¡Œï¼šä¿æŒæµåŠ¨æ€§åˆç†å……è£•ï¼Œæ”¯æŒå®ä½“ç»æµ',
                'summary': 'å¤®è¡Œè¡¨ç¤ºå°†ç»§ç»­å®æ–½ç¨³å¥çš„è´§å¸æ”¿ç­–ï¼Œä¿æŒæµåŠ¨æ€§åˆç†å……è£•ï¼ŒåŠ å¤§å¯¹å®ä½“ç»æµçš„æ”¯æŒåŠ›åº¦ï¼Œä¿ƒè¿›ç»æµé«˜è´¨é‡å‘å±•ã€‚',
                'source': 'å¤®è¡Œ',
                'time': current_time,
                'tags': ['å¤®è¡Œ', 'è´§å¸æ”¿ç­–', 'ç»æµ']
            },
            {
                'title': 'æ–°èƒ½æºè½¦é”€é‡æŒç»­å¢é•¿ï¼Œäº§ä¸šé“¾å—ç›Šæ˜æ˜¾',
                'summary': 'æ•°æ®æ˜¾ç¤ºï¼Œæ–°èƒ½æºæ±½è½¦é”€é‡æŒç»­é«˜å¢é•¿ï¼Œäº§ä¸šé“¾ä¸Šä¸‹æ¸¸ä¼ä¸šè®¢å•é¥±æ»¡ï¼Œç›¸å…³ä¸Šå¸‚å…¬å¸ä¸šç»©æœ‰æœ›æŒç»­æå‡ã€‚',
                'source': 'è¡Œä¸šå¿«è®¯',
                'time': current_time,
                'tags': ['æ–°èƒ½æº', 'æ±½è½¦', 'äº§ä¸šé“¾']
            },
            {
                'title': 'äººå·¥æ™ºèƒ½æ”¿ç­–æŒç»­åŠ ç ï¼Œç›¸å…³æ¦‚å¿µè‚¡æ´»è·ƒ',
                'summary': 'éšç€äººå·¥æ™ºèƒ½æ”¿ç­–æŒç»­åŠ ç ï¼ŒAIèŠ¯ç‰‡ã€ç®—åŠ›ã€åº”ç”¨ç­‰ç›¸å…³é¢†åŸŸæŠ•èµ„æœºä¼šå¢å¤šï¼Œæ¦‚å¿µè‚¡å¸‚åœºè¡¨ç°æ´»è·ƒã€‚',
                'source': 'ç§‘æŠ€å¿«è®¯',
                'time': current_time,
                'tags': ['äººå·¥æ™ºèƒ½', 'AIèŠ¯ç‰‡', 'ç§‘æŠ€']
            },
            {
                'title': 'åŒ»è¯ç”Ÿç‰©æ¿å—éœ‡è¡èµ°å¼ºï¼Œåˆ›æ–°è¯å¤‡å—å…³æ³¨',
                'summary': 'åŒ»è¯ç”Ÿç‰©æ¿å—ä»Šæ—¥éœ‡è¡èµ°å¼ºï¼Œåˆ›æ–°è¯ç ”å‘ä¼ä¸šå¤‡å—å¸‚åœºå…³æ³¨ã€‚æ”¿ç­–æ”¯æŒåŠ›åº¦åŠ å¤§ï¼Œè¡Œä¸šé•¿æœŸå‘å±•å‰æ™¯å‘å¥½ã€‚',
                'source': 'è¡Œä¸šå¿«è®¯',
                'time': current_time,
                'tags': ['åŒ»è¯', 'åˆ›æ–°è¯', 'ç”Ÿç‰©']
            },
            {
                'title': 'æˆ¿åœ°äº§æ”¿ç­–ä¼˜åŒ–è°ƒæ•´ï¼Œå¸‚åœºæƒ…ç»ªé€æ­¥å›æš–',
                'summary': 'å¤šåœ°æˆ¿åœ°äº§æ”¿ç­–è¿›ä¸€æ­¥ä¼˜åŒ–è°ƒæ•´ï¼Œå¸‚åœºæƒ…ç»ªé€æ­¥å›æš–ã€‚æˆ¿ä¼èèµ„ç¯å¢ƒæ”¹å–„ï¼Œè¡Œä¸šæœ‰æœ›è¿æ¥è¾¹é™…æ”¹å–„ã€‚',
                'source': 'åœ°äº§å¿«è®¯',
                'time': current_time,
                'tags': ['æˆ¿åœ°äº§', 'æ”¿ç­–', 'å¸‚åœº']
            },
            {
                'title': 'ç§‘åˆ›æ¿å†èèµ„åˆ¶åº¦ä¼˜åŒ–ï¼Œæ”¯æŒç§‘æŠ€åˆ›æ–°',
                'summary': 'ç§‘åˆ›æ¿å†èèµ„åˆ¶åº¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œæ›´å¥½åœ°æ”¯æŒç§‘æŠ€åˆ›æ–°ä¼ä¸šå‘å±•ã€‚æ”¿ç­–çº¢åˆ©æŒç»­é‡Šæ”¾ï¼Œç§‘åˆ›æ¿å¸å¼•åŠ›å¢å¼ºã€‚',
                'source': 'æ”¿ç­–å¿«è®¯',
                'time': current_time,
                'tags': ['ç§‘åˆ›æ¿', 'å†èèµ„', 'ç§‘æŠ€åˆ›æ–°']
            },
            {
                'title': 'å›½é™…æ²¹ä»·å¤§å¹…æ³¢åŠ¨ï¼Œèƒ½æºæ¿å—å…³æ³¨åº¦æå‡',
                'summary': 'å—åœ°ç¼˜æ”¿æ²»ç­‰å› ç´ å½±å“ï¼Œå›½é™…æ²¹ä»·å¤§å¹…æ³¢åŠ¨ã€‚èƒ½æºæ¿å—å…³æ³¨åº¦æå‡ï¼Œç›¸å…³è‚¡ç¥¨äº¤æ˜“æ´»è·ƒã€‚',
                'source': 'å›½é™…å¿«è®¯',
                'time': current_time,
                'tags': ['åŸæ²¹', 'èƒ½æº', 'å›½é™…']
            },
            {
                'title': 'åŒ—å‘èµ„é‡‘å‡€æµå…¥è¶…ç™¾äº¿ï¼Œå¤–èµ„çœ‹å¥½Aè‚¡å¸‚åœº',
                'summary': 'ä»Šæ—¥åŒ—å‘èµ„é‡‘å¤§å¹…å‡€æµå…¥è¶…ç™¾äº¿å…ƒï¼Œæ˜¾ç¤ºå¤–èµ„å¯¹Aè‚¡å¸‚åœºçš„ä¿¡å¿ƒã€‚å¤–èµ„é‡ç‚¹åŠ ä»“æ–¹å‘é›†ä¸­åœ¨æ¶ˆè´¹ã€ç§‘æŠ€ç­‰æ¿å—ã€‚',
                'source': 'èµ„é‡‘æµå‘',
                'time': current_time,
                'tags': ['åŒ—å‘èµ„é‡‘', 'å¤–èµ„', 'Aè‚¡']
            },
            {
                'title': 'åŠå¯¼ä½“è¡Œä¸šæ™¯æ°”åº¦æŒç»­å›å‡ï¼Œå›½äº§æ›¿ä»£åŠ é€Ÿ',
                'summary': 'åŠå¯¼ä½“è¡Œä¸šæ™¯æ°”åº¦æŒç»­å›å‡ï¼Œä¸‹æ¸¸éœ€æ±‚æ—ºç››ã€‚å›½äº§æ›¿ä»£è¿›ç¨‹åŠ é€Ÿï¼Œå›½å†…åŠå¯¼ä½“ä¼ä¸šè¿æ¥å‘å±•æœºé‡ã€‚',
                'source': 'è¡Œä¸šå¿«è®¯',
                'time': current_time,
                'tags': ['åŠå¯¼ä½“', 'èŠ¯ç‰‡', 'å›½äº§æ›¿ä»£']
            }
        ]

        # ä¸ºæ¯æ¡æ–°é—»ç”Ÿæˆæœç´¢URL
        for news in default_news_list:
            search_query = f"{news['title']} {current_date}"
            news['url'] = f"https://www.baidu.com/s?wd={search_query}"

        return default_news_list

    def get_all_news(self, limit: int = 30) -> Dict:
        """
        è·å–æ‰€æœ‰è´¢ç»æ–°é—»

        Args:
            limit: è·å–æ–°é—»æ•°é‡

        Returns:
            {
                'data': æ–°é—»åˆ—è¡¨,
                'update_time': æ›´æ–°æ—¶é—´
            }
        """
        # æŒ‰ä¼˜å…ˆçº§å°è¯•å¤šä¸ªæ–°é—»æº
        print("ğŸ“° æ­£åœ¨è·å–æœ€æ–°è´¢ç»æ–°é—»...")

        # 1. é¦–å…ˆå°è¯•æ–°æµªè´¢ç»7x24å¿«è®¯
        news_list = self.get_sina_finance_news(limit)

        # 2. å¦‚æœæ²¡æœ‰è·å–åˆ°ï¼Œå°è¯•ä¸œæ–¹è´¢å¯Œå¿«è®¯
        if not news_list:
            print("å°è¯•ä¸œæ–¹è´¢å¯Œå¿«è®¯...")
            news_list = self.get_eastmoney_flash_news(limit)

        # 3. å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•è…¾è®¯è´¢ç»
        if not news_list:
            print("å°è¯•è…¾è®¯è´¢ç»...")
            news_list = self.get_tencent_finance_news(limit)

        # 4. æœ€åä½¿ç”¨å®æ—¶æ•°æ®ç”Ÿæˆçš„æ–°é—»
        if not news_list:
            print("ä½¿ç”¨å®æ—¶å¸‚åœºæ•°æ®ç”Ÿæˆæ–°é—»...")
            news_list = self.get_realtime_news(limit)

        # 5. å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤æ–°é—»
        if not news_list:
            print("ä½¿ç”¨é»˜è®¤æ–°é—»...")
            news_list = self.get_default_news()

        print(f"âœ… æˆåŠŸè·å– {len(news_list)} æ¡æ–°é—»")

        return {
            'data': news_list,
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }


if __name__ == "__main__":
    # æµ‹è¯•
    collector = FinanceNewsCollector()
    result = collector.get_all_news()

    print("\n" + "="*80)
    print("ğŸ“° è´¢ç»æ–°é—»")
    print("="*80)

    for i, news in enumerate(result['data'], 1):
        print(f"\nã€{i}ã€‘{news['title']}")
        print(f"   æ¥æº: {news['source']} | æ—¶é—´: {news['time']}")
        if news.get('summary'):
            print(f"   æ‘˜è¦: {news['summary'][:100]}...")
        if news.get('tags'):
            print(f"   æ ‡ç­¾: {', '.join(news['tags'])}")
        print(f"   é“¾æ¥: {news['url']}")

    print(f"\nâ° æ›´æ–°æ—¶é—´: {result['update_time']}")
    print("="*80)
